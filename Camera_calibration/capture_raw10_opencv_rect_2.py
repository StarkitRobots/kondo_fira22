import arducam_mipicamera as arducam
import v4l2 #sudo pip install v4l2
import time
import numpy as np
import cv2 #sudo apt-get install python-opencv
import os
import yaml
import reload as re
import rpc, math

interface = rpc.rpc_network_slave(my_ip="010.000.000.038", port=0x1DBA)

def align_down(size, align):
    return (size & ~((align)-1))

def align_up(size, align):
    return align_down(size + align - 1, align)

def set_controls(camera):
    try:
        camera.set_control(v4l2.V4L2_CID_EXPOSURE, 800)  # 0 < 65535
        camera.set_control(v4l2.V4L2_CID_GAIN, 255)     # 0 < 255
        print('exposure:', camera.get_control(v4l2.V4L2_CID_EXPOSURE), 'gain: ', camera.get_control(v4l2.V4L2_CID_GAIN))
    except Exception as e:
        print(e)

camera = arducam.mipi_camera()
print("Open camera...")
camera.init_camera()
camera.set_mode(6) # chose a camera mode which yields raw10 pixel format, see output of list_format utility
fmt = camera.get_format()
width = fmt.get("width")
height = fmt.get("height")
print("Current resolution is {w}x{h}".format(w=width, h=height))
set_controls(camera)
with open("/home/pi/MIPI_Camera_old/RPI/python/Camera_calibration/calibration_matrix.yaml", "r")as f:
    data = yaml.load(f, yaml.Loader)
camera_matrix = np.asarray(data['camera_matrix'])
dist_coeff = np.asarray(data['dist_coeff'])
newcameramtx, roi=cv2.getOptimalNewCameraMatrix(camera_matrix, dist_coeff , (width,height), 1, (width,height))
roi_x, roi_y, roi_w, roi_h = roi
map1, map2 = cv2.initUndistortRectifyMap(camera_matrix, dist_coeff, None, newcameramtx, (width,height), cv2.CV_16SC2)
time.sleep(0.5)
filenumber = 0
timer = time.perf_counter()
counter = 0
def snapshot():
    image = camera.capture(encoding = 'raw')
    image = arducam.remove_padding(image.data, width, height, 10)
    image = arducam.unpack_mipi_raw10(image)
    image = image.reshape(height, width) << 6
    #print(image.size, image.dtype, image.shape)
    image = cv2.cvtColor(image, cv2.COLOR_BayerRG2BGR)
    #print(image.size, image.dtype, image.shape)
    #image1 = cv2.undistort(image, camera_matrix, dist_coeff, None, newcameramtx)
    image = cv2.remap(image, map1, map2, cv2.INTER_LINEAR)
    image = image[roi_y : roi_y + roi_h, roi_x : roi_x + roi_w]
    image = cv2.resize(image, (320,240))
    return image

def compress(img):
    encode_param = [int(cv2.IMWRITE_PNG_COMPRESSION ), 0]
    result, encimg = cv2.imencode('.png', img, encode_param)        # cv.imdecode(img, 1) for decoding
    return encimg

# This is called repeatedly by interface.stream_writer().
def stream_generator_cb():
    image = snapshot()
    cv2.imshow("Arducam", image)
    cv2.waitKey(10)
    #print('FPS:', 1/(time.perf_counter() - timer))
    #timer = time.perf_counter()
    #print(image)
    img = compress(image)
    #print(img)
    return img

# Transmits a stream of bytes()'s generated by stream_generator_cb to the master device.
def jpeg_image_stream_cb():
    interface.stream_writer(stream_generator_cb)
    
def find_orange_ball_on_green_field(img, data_dict):
    blobs = img.find_blobs([data_dict['orange ball']['th']],
                            pixels_threshold=data_dict['orange ball']['pixel'],
                            area_threshold=data_dict['orange ball']['area'],
                            merge=True, margin=10)
    if (len (blobs) == 1):
        blob = blobs [0]
        x , y , w , h = blob.rect()  # ball blob
        x1 = x + w                      # x1, y1, w1, h1-right rectangle
        y1 = y
        if x1 + w <= 320:
            w1 = w
        else:
            w1 = 320 - x1
        if x1 == 320:
            w1 = 1
            x1 = 319
        if y1 + 2 * h <= 240:
            h1 = 2 * h
        else:
            h1 = 240 - y1
        if y1 + h == 240:
            h1 = h
        y2 = y                         # x2, y2, w2, h2 - left rectangle
        if x - w > 0:
            x2 = x - w
            w2 = w
        else:
            x2 = 0
            w2 = x1 - x2
        if x1 == 0:
            x2 = 0
            w2 = 1
        y2 = y1
        h2 = h1
        x3 = x                          # x3, y3, w3, h3 - bottom rectangle
        y3 = y + h - 1
        w3 = w
        h3 = h1 - h + 1
        blob_p = []                     # right blobs
        blob_l = []                     # left blobs
        blob_n = []                     # bottom blobs
        blob_p = img.find_blobs([data_dict['green field']['th']],roi = [x1 , y1 , w1 , h1], pixels_threshold=7, area_threshold=7, merge=True)
        blob_l = img.find_blobs([data_dict['green field']['th']],roi = [x2 , y1 , w2 , h1], pixels_threshold=7, area_threshold=7, merge=True)
        blob_n = img.find_blobs([data_dict['green field']['th']],roi = [x3 , y3 , w3 , h3], pixels_threshold=7, area_threshold=7, merge=True)
        if len(blob_p) > 0 or len( blob_l ) > 0  or len( blob_n ) > 0:
            img.draw_rectangle(blob.rect(), color = (255, 0, 0))

def detect_Post_In_image(img, data_dict, post_color):
    post_thresholds =  [data_dict[post_color]['th']]
    for blob in img.find_blobs(post_thresholds, pixels_threshold = data_dict[post_color]['pixel'],
                              area_threshold = data_dict[post_color]['area'], merge=True):
        blob_Is_Post = False
        if blob.y() + blob.h() > 235 : continue         # blob connected to bottom of picture. No opportunity to recognize data
        else:
            if blob.w() > 314: continue         # blob connected to both sides of picture. No opportunity to recognize data
            for y in range (blob.y() + blob.h(), blob.y() + blob.h() + 5, 1 ):
                for x in range (blob.x(), blob.x() + blob.w(), 1 ):
                    a= image.rgb_to_lab(img.get_pixel(x , y))
                    is_green = (data_dict['green field']['th'][0] < a[0] < data_dict['green field']['th'][1]) and \
                               (data_dict['green field']['th'][2] < a[1] < data_dict['green field']['th'][3]) and \
                               (data_dict['green field']['th'][4] < a[2] < data_dict['green field']['th'][5])
                    is_white = (data_dict['white marking']['th'][0] < a[0] < data_dict['white marking']['th'][1]) and \
                               (data_dict['white marking']['th'][2] < a[1] < data_dict['white marking']['th'][3]) and \
                               (data_dict['white marking']['th'][4] < a[2] < data_dict['white marking']['th'][5])
                    if is_green == True or is_white == True : blob_Is_Post = True
                    if blob_Is_Post == True: break
                if blob_Is_Post == True: break
            if blob_Is_Post == True:
                img.draw_rectangle(blob.rect(), color = (255, 0, 0))

def find_all_blobs(img, data_dict):
    current = data_dict['current']
    for blob in img.find_blobs([data_dict[current]["th"]],
                    pixels_threshold=data_dict[current]["pixel"],
                    area_threshold=data_dict[current]["area"], merge=True):
        # These values depend on the blob not being circular - otherwise they will be shaky.
        if blob.elongation() > 0.5:
            img.draw_edges(blob.min_corners(), color=(255,0,0))
            img.draw_line(blob.major_axis_line(), color=(0,255,0))
            img.draw_line(blob.minor_axis_line(), color=(0,0,255))
        # These values are stable all the time.
        img.draw_rectangle(blob.rect())
        img.draw_cross(blob.cx(), blob.cy())
        # Note - the blob rotation is unique to 0-180 only.
        img.draw_keypoints([(blob.cx(), blob.cy(), int(math.degrees(blob.rotation())))], size=20)

thresholds = None
even_frame = False
def jpeg_image_stream(data):
    #pixformat, framesize = bytes(data).decode().split(",")
    #sensor.set_pixformat(eval(pixformat))
    #sensor.set_framesize(eval(framesize))
    interface.schedule_callback(jpeg_image_stream_cb)
    return bytes()

def binary_stream_generator_cb():
    global thresholds
    global even_frame
    data_dict = eval(thresholds)
    current = data_dict['current']
    img = snapshot()
    image = re.Image(img)
    if even_frame:
        image.img //= 257
        image.img = np.array(image.img, dtype = np.uint8)
        result = image.binary(data_dict[current]["th"])
        even_frame = False
    else:
        even_frame = True
        if data_dict["blob"] == 2:
            find_orange_ball_on_green_field(image, data_dict)
        elif data_dict["blob"] == 3:
            detect_Post_In_image(image, data_dict, "blue posts")
        elif data_dict["blob"] == 4:
            detect_Post_In_image(image, data_dict, "yellow posts")
        elif data_dict["blob"] == 5:
            detect_Post_In_image(image, data_dict, "white posts")
        elif data_dict["blob"] > 0:
            find_all_blobs(image, data_dict)
        result = image.img
    return compress(result)

def jpeg_image_binary_stream_cb():
    interface.stream_writer(binary_stream_generator_cb)

def jpeg_image_binary_stream(data):
    global thresholds
    thresholds = bytes(data).decode()
    print(thresholds)
    interface.schedule_callback(jpeg_image_binary_stream_cb)
    return bytes()

def jpeg_snapshot(data):
    img = sensor.snapshot()
    img1 = img.compress(quality=90)
    return img.bytearray()

def binary_snapshot(data):
    #img = sensor.snapshot()
    global even_frame
    thresholds = bytes(data).decode()  #(0, 100, -65, -37, 10, 64)
    print(thresholds)
    data_dict = eval(thresholds)
    current = data_dict['current']
    img = snapshot()
    image = re.Image(img)
    if even_frame:
        image.img //= 257
        image.img = np.array(image.img, dtype = np.uint8)
        result = image.binary(data_dict[current]["th"])
        even_frame = False
    else:
        even_frame = True
        if data_dict["blob"] == 2:
            find_orange_ball_on_green_field(image, data_dict)
        elif data_dict["blob"] == 3:
            detect_Post_In_image(image, data_dict, "blue posts")
        elif data_dict["blob"] == 4:
            detect_Post_In_image(image, data_dict, "yellow posts")
        elif data_dict["blob"] == 5:
            detect_Post_In_image(image, data_dict, "white posts")
        elif data_dict["blob"] > 0:
            find_all_blobs(image, data_dict)
        result = image.img
    return compress(result).tobytes()


# Register call backs.

#interface.register_callback(jpeg_image_stream)
interface.register_callback(jpeg_image_binary_stream)
#interface.register_callback(jpeg_snapshot)
interface.register_callback(binary_snapshot)

# Once all call backs have been registered we can start
# processing remote events. interface.loop() does not return.

interface.loop()

print("Close camera...")
camera.close_camera()

